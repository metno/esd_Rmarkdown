---
title: "SPECS-decadal-MOS"
author: "Rasmus Benestad"
date: "June 22, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Supporting material for Using statistical downscaling in decadal predictions

This document provides the source code (R) and the embedded plots for the investigation into the question whether model output statistics (MOS) can improve the skill of decadal forecasts. The term 'decadal' is loosely used for time scales between 1 and 10 years.

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

## The settings:

```{r initialise}
## Script that applies MOS to SPECS decadal forecasts

library(esd)
#library(knitr)
#purl('git/esd_Rmarkdown/SPECS/specs-decade-mos.Rmd', output='git/esd_Rmarkdown/SPECS/specs-decade-mos.R')
#library(ncdf)
setwd("~/R")

downloadfromunican <- FALSE    # Preparations - get the data
downscaledreanalysis <- TRUE  # SM: Assessment of large-small scale link
looexperiments <- TRUE        # Cross-validation MOS on forecasts
diagnoseFCST <- TRUE          # Show correlation & common EOFs of reanalysis+fcsts

#source("/home/rasmusb/disk1/SPECS/R/udg2esd_met.R") ## Upload udg2esd function

## This variable is needed because CDO did not fix the times properly
## for the predictands (EOBS)...
time = c(364, 729, 1095, 1460, 1825, 2190, 2556, 2921, 3286, 3651, 4017, 4382, 
    4747, 5112, 5478, 5843, 6208, 6573, 6939, 7304, 7669, 8034, 8400, 8765, 
    9130, 9495, 9861, 10226, 10591, 10956, 11322, 11687, 12052, 12417, 12783, 
    13148, 13513, 13878, 14244, 14609, 14974, 15339, 15705, 16070, 16435, 
    16800, 17166, 17531, 17896, 18261, 18627, 18992, 19357, 19722, 20088, 
    20453, 20818, 21183, 21549, 21914, 22279, 22644, 23010, 23375, 23740, 
    23921) ;


```

## Define the functions

Formatting and pre-processing the data

```{r functions}
#--- functions ---

fcst2field <- function(x,it0=1,im=1,verbose=FALSE) {

  if (verbose) print(paste('fcst2field',it0,im))
  lon <- x$xyCoords$x; nx <- length(lon)
  lat <- x$xyCoords$y; ny <- length(lat)
  index <- x$Dates$start; nt <- length(index)

## The data is scrambled with unconvntional x-y-order - generate unscramble index:
  usi <- t(matrix(1:(nx*ny),ny,nx))
  param <- x$Variable$varName
  unit <- attr(x$Variable,'units')
  if (verbose) print(paste(param,unit))

## one field
  df <- matrix(x$Data[it0,im,,,],nt,nx*ny)
  y <- zoo(df[,c(usi)],order.by=as.Date(index))
  Y <- as.field(y,param=param,unit=unit,lon=lon,lat=lat,
              info=paste('member',im ,'initialisation',it0))
  if (verbose) print('---')
  invisible(Y)
}

```

Extracting the correct predictor information from the data 

```{r xpredictor}

## Function to extract a subset and organise the predictor data
## for all ensemble members
Xpredictor <- function(x,m=1:3,it=NULL,is=NULL,mask=FALSE,
                       FUN='mean',verbose=FALSE) {
  if (verbose) print('Xpredictor')
  ## x is the data, m is the forecast interval (years), and it
  ## specifies e.g. months
  ## Get the dimensions of the data structure
  d <- dim(x$Data)
  if (verbose) {print(summary(x)); print(d)}
  ## initialisations members times nx ny

  ## Prepare one member per loop
  for (im in 1:d[2]) {
    index <- x$Dates$start; nt <- length(index); jj <- 1
    for (ii in m) {
      if (verbose) print(paste('member',im,'initialisation',ii))
      ## Read the entire field
      y1 <- fcst2field(x,it0=10-ii,im=im,verbose=verbose)
      ## Extract a sub-region
      y1 <- subset(y1,is=is)
      ## If it!=NULL select subset of the year 
      y1 <- aggregate(subset(y1,it=it),year,FUN)
      ## If mask, remove the land component
      if (mask) y1 <- mask(y1,land=TRUE)
      if (verbose) {print(index(y1)); print(index(lag(zoo(y1),k=-ii)))}
      ## Let Y1 contain the end results: sum the different lead times
      if (jj==1)  Y1 <- zoo(y1) else
                  Y1 <- zoo(Y1) + zoo(lag(y1,k=-ii))
      jj <- jj + 1
    }
    ## Divide by the number of initialisations to get the forecast interval mean
    coredata(Y1) <- coredata(Y1)/length(m)
    ## Set the appropriate attributes and class
    if (verbose) {print('Set the appropriate attributes'); print(names(attributes(y1)))}
    Y1 <- attrcp(y1,Y1)
    if (verbose) print(paste('Set the appropriate class',class(y1),collapse='-'))
    class(Y1) <- class(y1)
    if (verbose) print(class(y1))
    
    ## The index is set by the year and the calendar month/day reflects
    ## member number
    if (verbose) print(yearY1)
    if (d[2]<=12) index(Y1) <- as.Date(paste(year(Y1),im,'01',sep='-'),
                                       origin = as.Date("1950-01-01")) else
                  index(Y1) <- as.Date(paste(year(Y1),'01-01',sep='-')+im,
                                       origin = as.Date("1950-01-01"))
    if (verbose) print(index(Y1))
    
    ## Outside the loop for each member: combine the different members
    if (im==1) Y <- zoo(Y1) else
               Y <- c(zoo(Y),zoo(Y1))
  }

  Y <- attrcp(y1,Y,ignore='dimnames')
  attr(Y,'dimnames') <- NULL
  ## Need to subsample every m year
  it <- is.element(year(Y),seq(min(year(Y)),max(year(Y)),by=max(m)))
  Y <- subset(Y,it=it)
  class(Y) <- class(y1)
  if (verbose) {
    print(paste(max(m),'-year intervals for ',d[2],' ensemble members',sep=''))
    print(index(Y))
  }
  attr(Y,'longitude') <- lon(y1)
  attr(Y,'latitude') <- lat(y1)
  attr(Y,'dimensions') <- c(length(lon(y1)),length(lat(y1)),length(index(Y)))
  ## Keep track of how the members are represented
  attr(Y,'n_members') <- d[2]
  if (d[2]<=12) attr(Y,'member_by') <- 'month' else
                attr(Y,'member_by') <- 'day'
  ## The end-result contains a field object with
  if (verbose) print('Xpredictor successfully completed!')
  invisible(Y)
}

```

Aggregate daily data from the EOBS data, using CDO (because the data size is too big for R).

```{r aggregate}
aggregatedailyfield <- function(fname,cline='cdo monmean',
                                output='mu_0.25deg_reg.nc') {
  print('This function only works if you have CDO installed')
  print(paste(cline,fname,output))
  system(paste(cline,fname,output))
  x <- retrieve(output)
  invisible(x)
}

```

Estimating the wet-day mean from the EOBS data using CDO (because the data size is too big for R).


```{r wetdaymean}
wetdaymean <- function(ifile,cline='cdo yearmean',fname='wetdaymean.nc') {
  print('calculate mask')
  system(paste('cdo gtc,1',ifile,'mask.nc'))
  ## her blir ofile en mask med 1 i alle tidsskritt med data over konstanten (satt til 0),
  ## og verdi 0 i alle andre
  print('apply mask')
  system(paste('cdo ifthen mask.nc',ifile, fname))
  ## her appliseres masken på ifile og lagres i ofile. (Øvrige punkter får verdien NA.)
  
  ##Disse går å kombinere til en rad:
  ##  print(paste('cdo ifthen -gtc,0',ifile,ifile,fname))
  ##  system(paste('cdo ifthen -gtc,0',ifile,ifile,fname))
  X <- aggregatedailyfield(fname=fname,cline=cline)
  Y <- aggregatedailyfield(fname=,'mask.nc',cline=cline,output='fw_0.25deg_reg.nc')
  file.remove(fname); file.remove('mask.nc')
}

```


function setting up the experiment:

```{r D53exp}
## LOO experimtent: X is the predictor and Y is the predictand
D53Exp <- function(X,Y,m=c(1,3),it=NULL,is=NULL,mask=FALSE,verbose=TRUE) {
  if (verbose) print('D53Exp: Prepare predictor')
  ## Prepare the predictor:
  X <- Xpredictor(X,m=m,it=it,is=is,mask=mask,verbose=verbose)
  ## Prepare the predictand: repeat the same precitand to match the
  ## ensemble members - give same time stamp/date:
  if (verbose) print(paste('Predictand',varid(Y)))
  n <- attr(X,'n_members')
  Y0 <- Y

  ## Aggregate the predictand over the forecast interval as done in Xpredictor
  if (verbose) print(paste('Aggregate over years ',m,collapse='-'))
  for (j in 1:length(m)) {
    if (j==1) y <- zoo(Y) else
              y <- y + lag(zoo(Y),k=-m[j])
  }
  coredata(y) <- coredata(y)/length(m)
  if (verbose) {print('dim after aggragation');print(dim(Y0)); print(dim(y))}

  ## repeat the observations with corrsponding time stamps as the ensemble members of the forecast
  if (verbose) print('repeat predictand')
  for (i in 1:n) {
    if (verbose) print(paste('predictand',i))
    if (attr(X,'member_by')=='month')
      index(y) <- as.Date(paste(year(y),i,'01',sep='-'),
                          origin = as.Date("1950-01-01")) else
      index(y) <- as.Date(paste(year(y),'01-01',sep='-')+i,
                          origin = as.Date("1950-01-01"))
    if (verbose) print(index(y))
    if (i==1) Y <- y else Y <- c(Y,y)
  }
  ## Copy all attributes etc.
  Y <- attrcp(Y0,Y)
  class(Y) <- c('field','day','zoo')
  attr(Y,'dimensions') <- c(length(lon(Y0)),length(lat(Y0)),length(index(Y)))
  if (verbose) print('predictand sucessfully processed')
  ## The experiment
  xeof <- EOF(mask(X,land=TRUE))
  yrs <- year(X)[is.element(year(X),year(Y))]
  yrs <- yrs[!duplicated(yrs)]
  if (verbose) {print(yrs); print('LOO x-val...')}
  ## LOO
  for (it in 1:length(yrs)) {
    ## set index to exclude all members for the same evaluation interval
    iloo <- !is.element(year(Y),yrs[it])
    yloo <- subset(Y,it=iloo)
    if (verbose) {
      print(paste('LOO: it=',it,'years:'))
      print(table(year(yloo)))
    }
    class(yloo) <- class(X)
    yeof <- EOF(yloo,n=4)
    ## Some hacking needed to ensure that subset doesn't change the index type to year.
    class(yeof)[3] <- 'day';  class(xeof)[3] <- 'day';
    ds.loo <- DS(yeof,xeof,verbose=verbose)
    ## Extract the forecast for the evaluation interval:
    if (verbose) print('reconstruct field')
    jloo <- is.element(year(xeof),yrs[it])
    xval <- subset(as.field(predict(ds.loo,newdata=xeof)),it=jloo)
    ## combine each LOO result into one series:
    if (it==1) XVAL <- xval else
               XVAL <- c(XVAL,xval)
  }
  if (verbose) print('LOO completed')
  XVAL <- attrcp(Y0,XVAL); class(XVAL) <- class(Y)
  attr(XVAL,'dimensions') <- c(attr(Y,'dimensions')[1:2],length(index(XVAL)))
  ## Plot the correlation map between LOO results and original:
  rmap <- corfield(aggregate(XVAL,year,'mean'),aggregate(Y,year,'mean'),plot=FALSE)
  map(rmap,colbar=list(breaks=seq(-1,1,by=0.1),pal='t2m',rev=TRUE),type='fill',new=FALSE)
  invisible(XVAL)
}

```

Extract the {\em m}-year annual mean MOS-based forecast.


```{r mannualfcst}
mannualfcst <- function(x,l=1,it=NULL,is=NULL,mask=FALSE,verbose=FALSE) {
  ## A function that extract l-year aggregated data from the forecasts
  ## It uses Xpredictor to represent each ensemble member as a different
  ## calendar month, and needs to seperate these months and aggregate them
  ## seperately before synthesising a new corresponding field object with
  ## multi-year aggregated values.
  
  X <- Xpredictor(x,m=l,it=it,is=is,mask=mask,verbose=verbose)
  n <- attr(X,'n_members')
  if (attr(X,'member_by')=='month') {
    if (verbose) print('separate ensemble members by calendar month')
    m <- as.integer(rownames(table(month(X))))
    j <- 1
    for (i in m) {
      y <- pentad(subset(X,it=month.abb[i]),l=l)
      index(y) <- as.Date(paste(year(y),i,'01',sep='-'))
      if (j==1) Y <- zoo(y) else
                Y <- c(Y,zoo(y))
      j <- j+1
    }
  }
  Y <- attrcp(X,Y)
  class(Y) <- class(X)
  attr(Y,'dimnames') <- NULL
  invisible(Y)
}

```

Compare the {\em m}-year annual mean MOS-based forecast with corresponding EOBS statistics

```{r compare}
comparemannual <- function(tas_DECA,reanalysis='~/Downloads/air.mon.mean.nc',mask=TRUE,l= 3,eofs=NULL) {

  X <- mannualfcst(tas_DECA,l=l,mask=mask,verbose=TRUE)
  Y <- pentad(retrieve(reanalysis,lon=range(lon(X)),lat=range(lat(X))),l=l)

  if (is.T(X)) varid <- 'tas' else {
    varid <- 'psl'
    coredata(Y) <- 100*coredata(Y)
    attr(X,'unit') <- 'Pa'
    attr(Y,'unit') <- 'Pa'
  }
  if (mask) land <- '' else land <- '-nomask'
  
## Compare the multi-annual scale ensemble mean forecast with the NCEP/NCAL reanalysis
  Xm <- aggregate(X,year,'mean')
  index(Xm) <- year(Xm)
  class(Y) <- class(Xm)

  ## Apply an EOF-filter to emphasise only the large scale anomalies:
  if (!is.null(eofs)) {
    print(paste('Only keep the large-scale structures; EOFs:',paste(eofs,collapse=' ,')))
    Xm.eofs <- subset(EOF(Xm),ip=eofs)
    Xm <- eof2field(Xm.eofs)
    land <- paste(land,'eof_',paste(eofs,collapse='+'))
  }

  rmap <- corfield(Xm,Y,new=FALSE)
  if (l==1) figlab(paste(l,'year'),ypos=0.999) else figlab(paste(l,'years'),ypos=0.999)
  
## Generate a common EOF

  if (mask) Z <- mask(Y,land=TRUE) else Z <- Y
  Z <- subset(Z,it=range(year(X)))
  for (i in 1:10) {
    z <- subset(X,it=month.abb[i])
    index(z) <- year(z)
    Z <- combine(Z,z)
  }
  ceof <- EOF(Z)

  plot(ceof,type='fill',new=FALSE)
  figlab(paste(l,'years'),ypos=0.999)
  invisible(rmap)
## Generate a common EOF
}

```

Get the diagnostics of the MOS forecasts

```{r diagnose}
diagnoseMOS <- function(results,y,l=1) {
  print(paste('diagnoseMOS',results))
  load(results)  
  eval(parse(text=paste('zmos <-',substr(results,14,nchar(results)-4))))
  attr(zmos,'variable') <- varid(y)
  print(range(year(zmos)))
  y <- pentad(y,it0=min(year(zmos)),l=l)
  print(index(y))
  print(index(zmos))
  print('ensemble mean: aggregate(.)')
  ## Different ensemble emmbers are represented as calendar months
  Z <- aggregate(zmos,year,'mean')
  index(Z) <- year(Z)
  print('correlation: ensemble mean FCST & reanalysis')
  r <- corfield(Z,y,plot=FALSE)
  map(r,colbar=list(breaks=seq(-1,1,by=0.1),pal='t2m',rev=TRUE),type='fill',new=FALSE)
  figlab('EOBS+ensemble mean MOS',ypos=0.999)

  print('Common EOFs')
  y <- subset(y,it=range(year(Z)))
  ceof <- EOF(combine(y,Z))

  plot(ceof,type='fill',new=FALSE)
  figlab('EOBS+MOS',xpos=0.8,ypos=0.999)
  figlab('ensemble mean MOS (red) + observed (black)')
  
  plot(diagnose(ceof),new=FALSE)
  figlab('EOBS+MOS')
    
  print('return correlation statistics')
  invisible(quantile(c(r),na.rm=TRUE))
}

```

Check the space-time scale dependency.

```{r scales}
scaledependency <- function(x) {
  print('scaledependency')
  ## compare time and spatial scales
  stopifnot(inherits(x,"field"))
  d <- attr(x,'dimensions')
  ## convert zoo's 2D to 3D data
  y <- t(x); dim(y) <- d
  nd <- trunc(min(d[1:2])/2)
  scales <- matrix(rep(nd*trunc(d[3]/2)),nd,trunc(d[3]/2))
  timeseries <- matrix(rep(nd*d[3]),nd,d[3])
  print(dim(scales))
  for (i in 1:nd) {
    ix <- nd + -i:i; iy <- nd + -i:i
    ix[ix < 1] <- 1; ix[ix > d[1]] <- d[1]
    iy[iy < 1] <- 1; iy[iy > d[2]] <- d[2]
    print(c(i,range(ix),range(iy)))
    z <- coredata(y[ix,iy,])
    dim(z) <- c((1+2*i)^2,d[3])
    z <- colMeans(z)
    f <- spectrum(z,method="pgram",plot=FALSE)$spec
    ## Save smoothed filter and 
    #scales[i,] <- filter(rev(f[1:trunc(d[3]/2)]),rep(1,3)/3)
    scales[i,] <- rev(f[1:trunc(d[3]/2)])
    timeseries[i,] <- z
  }
  attr(scales,'timescales') <- rev(1/(12*spectrum(z,plot=FALSE)$freq[1:trunc(d[3]/2)]))
  attr(scales,'unit_time') <- 'year'
  attr(scales,'gridboxes') <- (1+2*(1:nd))^2
  attr(scales,'unit_gridboxes') <- 'number_of_boxes'
  attr(scales,'timeseries') <- zoo(t(timeseries),order.by=index(x))
  image(attr(scales,'timescales'),attr(scales,'gridboxes'),t(scales))
  invisible(t(scales))
}

##------------------------------------------------------------------------
```

## Implementation

```{r implement}
## Get the predictand: the gridded wet-day mean preciptation from the EOBS data

## Get the data:

if (downloadfromunican) {
  print('Get data from oceano.macc.unican.es')
  datadir <- 'SPECS-decadal'
  if (!file.exists('SPECS-decadal')) {
    dir.create('SPECS-decadal')
    system(paste('rsync -rtuv --progress ',datadir,'lpcaron@oceano.macc.unican.es:~/'))
  }
}

print('Get the predictands: mu & fw from EOBS')
if (!file.exists('~/data/mu_0.25deg_reg.nc'))
  mu.eobs <-  wetdaymean('~/data/data.ECAD/rr_0.25deg_reg.nc') else
  mu.eobs <- retrieve('~/storeA/mu_0.25deg_reg.nc')
fw.eobs <- retrieve('~/storeA/fw_0.25deg_reg.nc')
attr(mu.eobs,'variable') <- 'mu'
attr(fw.eobs,'variable') <- 'fw'
attr(fw.eobs,'unit') <- 'fraction'
#index(fw.eobs) <- year(as.Date(time,origin = as.Date("1950-01-01")))
#index(mu.eobs) <- year(as.Date(time,origin = as.Date("1950-01-01")))


```


```{r ds}

## Display the downscaled reanalysis data for assessing link between large and small scales  - in the shape of EOFs
if (downscaledreanalysis) {
  mu.eof <- EOF(mu.eobs)
  plot(mu.eof,colbar=list(pal='t2m',breaks=seq(-0.02,0.02,by=0.001),type='fill',rev=TRUE),new=FALSE)
  figlab('EOBS',ypos=0.999)

## The wet-day frequency:
  
  fw.eof <- EOF(fw.eobs)
  plot(fw.eof,colbar=list(pal='t2m',breaks=seq(-0.01,0.015,by=0.001),type='fill',rev=TRUE),new=FALSE)
  figlab('EOBS',ypos=0.999)

## Test to examine the link between large-scale temperature and wet-day mean precip
## Derive the saturation vapour pressure from temperature
## retrieve did not get the right time stamp:
  es <- annual(C.C.eq(retrieve('~/R/air.mon.mean.nc',lon=c(-60,40),lat=c(20,70))))
  es.eof <- EOF(mask(es,land=TRUE))

## Also get the mean sea-level pressure for the wet-day frequency 
  slp <- annual(retrieve('~/R/slp.mon.mean.nc',lon=c(-60,40),lat=c(20,70)))
  slp.eof <- EOF(slp)

## Additional diagnostics: canonical correlation analysis:
  cca <- CCA(es.eof,slp.eof)
  plot(cca,colbar1=list(breaks=seq(-300,300,by=10)),colbar2=list(breaks=seq(-20,20,by=1)),new=FALSE)
  figlab(expression(paste('NCEP/NCAR: ',e[s](T),'-slp')))

  class(mu.eof) <- class(es.eof)
  mu.ds <- DS(mu.eof,es.eof)
  class(fw.eof) <- class(slp.eof)
  fw.ds <- DS(fw.eof,slp.eof)

  plot(mu.ds,colbar1=list(breaks=seq(-0.025,0.025,by=0.005),rev=TRUE),
       colbar2=list(breaks=seq(-350,350,by=25)),type='fill',new=FALSE)
  figlab('ESD(NCEP/NCAR)',ypos=0.999)

  plot(fw.ds,colbar1=list(breaks=seq(0.0,0.02,by=0.001),rev=TRUE),
       colbar2=list(breaks=seq(-20,20,by=2.5)),type='fill',new=FALSE)
  figlab('ESD(NCEP/NCAR)',ypos=0.999)
}

```


```{r data}

## The predictor: Convert from UDG to field.object:
## psl_DECA
## tas_DECA
##slp <- udg2esd(psl_DECA)
##t2m <- udg2esd(tas_DECA)
##> summary(psl_DECA)
##                    Length   Class  Mode     
##Variable                   2 -none- list     
##Data                79704000 -none- numeric  
##xyCoords                   2 -none- list     
##Dates                      2 -none- list     
##InitializationDates        9 -none- list     
##Members                   10 -none- character
##
##> dim(psl_DECA$Data)
## [1]   9  10 480  41  45

print('Get the decadal predictors saved locally in "~/data/gfdl_DECA.rda"')
load('~/R/mme_DECA.rda')
```

Leave-one-out cross-validation experiments

```{r loo}

if (looexperiments) {
## Carry out a LOO cross-validation experiment
  print('Check results for LOO experiment - if absent do it')
  if (!file.exists('specsdecadal.z.fw.y1.rda')) {
    print('do specsdecadal.z.fw.y1.rda')
    z.fw.y1 <- D53Exp(X=psl_DECA,Y=fw.eobs,m=1,it=NULL,is=NULL,mask=FALSE)
    save(file='specsdecadal.z.fw.y1.rda',z.fw.y1)
    rm("z.fw.y1"); gc(reset=TRUE)
  }
  if (!file.exists('specsdecadal.z.mu.y1.rda')) {
    print('do specsdecadal.z.mu.y1.rda')
    z.mu.y1 <- D53Exp(X=tas_DECA,Y=mu.eobs,m=1,it=NULL,is=NULL,mask=TRUE)
    save(file='specsdecadal.z.mu.y1.rda',z.mu.y1)
    rm("z.mu.y1"); gc(reset=TRUE)
  }
  if (!file.exists('specsdecadal.z.fw.y1.3.rda')) {
    print('do specsdecadal.z.fw.y1.3.rda')
    z.fw.y1.3 <- D53Exp(X=psl_DECA,Y=fw.eobs,m=1:3,it=NULL,is=NULL,mask=FALSE)
    save(file='specsdecadal.z.fw.y1.3.rda',z.fw.y1.3)
    rm("z.fw.y1.3"); gc(reset=TRUE)
  }
  if (!file.exists('specsdecadal.z.mu.y1.3.rda')) {
    print('do specsdecadal.z.mu.y1.3.rda')
    z.mu.y1.3 <- D53Exp(X=tas_DECA,Y=mu.eobs,m=1:3,it=NULL,is=NULL,mask=TRUE)
    save(file='specsdecadal.z.mu.y1.3.rda',z.mu.y1.3)
    rm("z.mu.y1.3"); gc(reset=TRUE)
  }
  if (!file.exists('specsdecadal.z.fw.y1.5.rda')) {
    print('do specsdecadal.z.fw.y1.5.rda')
    z.fw.y1.5 <- D53Exp(X=psl_DECA,Y=fw.eobs,m=1:5,it=NULL,is=NULL,mask=FALSE)
    save(file='specsdecadal.z.fw.y1.5.rda',z.fw.y1.5)
    rm("z.fw.y1.5"); gc(reset=TRUE)
  }
  if (!file.exists('specsdecadal.z.mu.y1.5.rda')) {
    print('do specsdecadal.z.mu.y1.5.rda')
    z.mu.y1.5 <- D53Exp(X=tas_DECA,Y=mu.eobs,m=1:5,it=NULL,is=NULL,mask=TRUE)
    save(file='specsdecadal.z.mu.y1.5.rda',z.mu.y1.5)
    rm("z.mu.y1.5"); gc(reset=TRUE)
  }
  if (!file.exists('specsdecadal.z.fw.y1.9.rda')) {
    print('do specsdecadal.z.fw.y1.9.rda')
     z.fw.y1.9 <- D53Exp(X=psl_DECA,Y=fw.eobs,m=1:9,it=NULL,is=NULL,mask=FALSE)
     save(file='specsdecadal.z.fw.y1.9.rda',z.fw.y1.9)
     rm("z.fw.y1.9"); gc(reset=TRUE)
   }
  if (!file.exists('specsdecadal.z.mu.y1.9.rda')) {
    print('do specsdecadal.z.mu.y1.9.rda')
    z.mu.y1.9 <- D53Exp(X=tas_DECA,Y=mu.eobs,m=1:9,it=NULL,is=NULL,mask=TRUE)
    save(file='specsdecadal.z.mu.y1.9.rda',z.mu.y1.9)
    rm("z.mu.y1.9"); gc(reset=TRUE)
  }

## Diagnostics:
  print('diagnose the MOS results')
  load('specsdecadal.z.mu.y1.3.rda')
  it0 <- range(year(z.mu.y1.3))
  print(paste('time period',paste(it0,collapse='-')))
  score.mu.y1 <- diagnoseMOS('specsdecadal.z.mu.y1.rda',mu.eobs)
  score.fw.y1 <- diagnoseMOS('specsdecadal.z.fw.y1.rda',fw.eobs)
  score.mu.y1.3 <- diagnoseMOS('specsdecadal.z.mu.y1.3.rda',mu.eobs,l=3)
  score.fw.y1.3 <- diagnoseMOS('specsdecadal.z.fw.y1.3.rda',fw.eobs,l=3)
  score.mu.y1.5 <- diagnoseMOS('specsdecadal.z.mu.y1.5.rda',mu.eobs,l=5)
  score.fw.y1.5 <- diagnoseMOS('specsdecadal.z.fw.y1.5.rda',fw.eobs,l=5)
  score.mu.y1.9 <- diagnoseMOS('specsdecadal.z.mu.y1.9.rda',mu.eobs,l=9)
  score.fw.y1.9 <- diagnoseMOS('specsdecadal.z.fw.y1.9.rda',fw.eobs,l=9)
  while (dev.cur()>1) dev.off()
## Repeat and make a table of the results...
  
}
  
```

Diagnose the forecasts

```{r diagnosefcst}
## Common EOFs to diagnose the results?

if (diagnoseFCST) {
  comparemannual(tas_DECA,mask=TRUE,l= 1)
  comparemannual(tas_DECA,mask=TRUE,l= 2)
  comparemannual(tas_DECA,mask=TRUE,l= 4)
  comparemannual(tas_DECA,mask=TRUE,l= 5)
  comparemannual(tas_DECA,mask=TRUE,l= 6)
  comparemannual(tas_DECA,mask=TRUE,l= 7)
  comparemannual(tas_DECA,mask=TRUE,l= 8)
  comparemannual(psl_DECA,reanalysis='slp.mon.mean.nc',mask=FALSE,l= 1)
  comparemannual(psl_DECA,reanalysis='slp.mon.mean.nc',mask=FALSE,l= 2)
  comparemannual(psl_DECA,reanalysis='slp.mon.mean.nc',mask=FALSE,l= 3)
  comparemannual(psl_DECA,reanalysis='slp.mon.mean.nc',mask=FALSE,l= 4)
  comparemannual(psl_DECA,reanalysis='slp.mon.mean.nc',mask=FALSE,l= 5)
  comparemannual(psl_DECA,reanalysis='slp.mon.mean.nc',mask=FALSE,l= 6)
  comparemannual(psl_DECA,reanalysis='slp.mon.mean.nc',mask=FALSE,l= 7)
  comparemannual(psl_DECA,reanalysis='slp.mon.mean.nc',mask=FALSE,l= 8)
  rmap.1.10.mask.3 <- comparemannual(tas_DECA,mask=TRUE,l= 3, eofs=1:10)
  rmap.1.10.nomask.3 <- comparemannual(tas_DECA,mask=FALSE,l= 3, eofs=1:10)
}
```

```{r rmaps}
  ## Test the forecasts of the larg-scale anomalies/gravest EOFs
  rmap.mask.3 <- comparemannual(tas_DECA,mask=TRUE,l= 3)
  rmap.nomask.3 <- comparemannual(tas_DECA,mask=FALSE,l= 3)
  rmap.1.3.mask.3 <- comparemannual(tas_DECA,mask=TRUE,l= 3, eofs=1:3)
  rmap.1.3.nomask.3 <- comparemannual(tas_DECA,mask=FALSE,l= 3, eofs=1:3)
  rmap.1.5.nomask.3 <- comparemannual(tas_DECA,mask=FALSE,l= 3, eofs=1:5)
  rmap.1.2.nomask.3 <- comparemannual(tas_DECA,mask=FALSE,l= 3, eofs=1:2)
  rmap.1.9.nomask.3 <- comparemannual(tas_DECA,mask=FALSE,l= 3, eofs=1:9)
```

```{r rdiff}
  rdiff <- rmap.1.3.nomask.3 - rmap.nomask.3
  map(rdiff,new=FALSE)
  figlab('TAS forecast (3 years): correlations EOFs 1-3 vs full field',ypos=0.99)

  rdiff <- rmap.1.3.mask.3 - rmap.mask.3
  map(rdiff,new=FALSE)
  figlab('TAS forecast (3 years): correlations EOFs 1-3 vs full field',ypos=0.99)

  rdiff <- rmap.1.5.nomask.3 - rmap.nomask.3
  map(rdiff,new=FALSE)
  figlab('TAS forecast (3 years): correlations EOFs 1-5 vs full field',ypos=0.99)

  rdiff <- rmap.1.2.nomask.3 - rmap.nomask.3
  map(rdiff,new=FALSE)
  figlab('TAS forecast (3 years): correlations EOFs 1-2 vs full field',ypos=0.99)

  rdiff <- rmap.1.9.nomask.3 - rmap.nomask.3
  map(rdiff,new=FALSE)
  figlab('TAS forecast (3 years): correlations EOFs 1-9 vs full field',ypos=0.99)
```


```{r t2m scales}
## Scaling dependency: time - space
t2m <- retrieve('~/Downloads/air.mon.mean.nc',lon=c(-90,60),lat=c(-20,80))
t2m <- anomaly(t2m)
zst <- scaledependency(t2m)
#zst[,1] <- NA
d <- dim(zst)

image(attr(zst,'timescales'),attr(zst,'gridboxes'),t(t(zst)/colMeans(zst)),
      main='Surface temperature: spectral power',
      xlab='Temporal scale (years)',ylab='spatial scale (grid boxes)')
contour(attr(zst,'timescales'),attr(zst,'gridboxes'),zst,add=TRUE)

plot(attr(zst,'timeseries'),plot.type='single',col=colscal(20),main='T(2m)')

```

## Repeat for mean sea-level pressure (SLP)

```{r slp}

## Repeat for SLP
slp <- retrieve('~/data/slp.mon.mean.nc',lon=c(-90,60),lat=c(-20,80))
slp <- anomaly(slp)
yst <- scaledependency(slp)
image(attr(yst,'timescales'),attr(yst,'gridboxes'),t(t(yst)/colMeans(yst)),
      main='Mean sea-level pressure: spectral power',
      xlab='Temporal scale (years)',ylab='spatial scale (grid boxes)')
contour(attr(yst,'timescales'),attr(yst,'gridboxes'),yst,add=TRUE)

plot(attr(yst,'timeseries'),plot.type='single',col=colscal(20),main='SLP')


## Distributions? Ensemble mean and spread -> dnorm()?

## Scores: SPECS libraries?

## The dependency of number of heavy precip event on frequency/sample size


ns <- trunc(10*1.1^seq(1,100,by=1))
nx <- rep(NA,length(ns))
for (i in 1:length(ns)) nx[i] <- sum(rexp(ns[i],rate=1/7) > 50)
plot(ns,nx,main='Number of extreme cases (x>50)',
     xlab='sample size',ylab=expression(n[x>50]),
     sub=expression(paste('exponential distribution: ',mu,'=7')))

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
